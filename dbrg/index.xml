<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Database Reading Group | DIPr Lab at PSU</title>
    <link>https://diprlab.github.io/dbrg/</link>
      <atom:link href="https://diprlab.github.io/dbrg/index.xml" rel="self" type="application/rss+xml" />
    <description>Database Reading Group</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 20 Aug 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://diprlab.github.io/media/logo_hu_f67add51057eb433.png</url>
      <title>Database Reading Group</title>
      <link>https://diprlab.github.io/dbrg/</link>
    </image>
    
    <item>
      <title>Summer 2025 Week 4</title>
      <link>https://diprlab.github.io/dbrg/events/2025/summer/04/</link>
      <pubDate>Wed, 20 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://diprlab.github.io/dbrg/events/2025/summer/04/</guid>
      <description>&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Title
    &lt;/td&gt;
    &lt;td&gt;
      TSB-UAD: An End-to-End Benchmark Suite for Univariate Time-Series Anomaly Detection
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;
      Authors
    &lt;/td&gt;
    &lt;td&gt;
      John Paparrizos ,Yuhao Kang , Paul Boniol , Ruey S. Tsay ,Themis Palpanas , Michael J. Franklin
    &lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
   &lt;td&gt;
      Abstract
    &lt;/td&gt;
    &lt;td&gt;
      The detection of anomalies in time series has gained ample academic and industrial attention. However, no comprehensive benchmark exists to evaluate time-series anomaly detection methods. It is common to use (i) proprietary or synthetic data, often biased to support particular claims; or (ii) a limited collection of publicly available datasets. Consequently, we often observe methods performing exceptionally well in one dataset but surprisingly poorly in another, creating an illusion of progress. To address the issues above, we thoroughly studied over one hundred papers to identify, collect, process, and systematically format datasets proposed in the past decades. We summarize our eort in TSB-UAD, a new benchmark to ease the evaluation of univariate time-series anomaly detection methods. Overall, TSB-UAD contains 13766 time series with labeled anomalies spanning dierent domains with high variability of anomaly types, ratios, and sizes. TSB-UAD includes 18 previously proposed datasets containing 1980 time series and we contribute two collections of datasets. Specically, we generate 958 time series using a principled methodology for transforming 126 time-series classication datasets into time series with labeled anomalies. In addition, we present data transformations with which we introduce new anomalies, resulting in 10828 time series with varying complexity for anomaly detection. Finally, we evaluate 12 representative methods demonstrating that TSB-UAD is a robust resource for assessing anomaly detection methods. We make our data and code available at www.timeseries.org/TSB-UAD. TSB-UAD provides a valuable, reproducible, and frequently updated resource to establish a leaderboard of univariate time-series anomaly detection methods.
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Summer 2025 Week 3</title>
      <link>https://diprlab.github.io/dbrg/events/2025/summer/03/</link>
      <pubDate>Wed, 06 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://diprlab.github.io/dbrg/events/2025/summer/03/</guid>
      <description>&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Title
    &lt;/td&gt;
    &lt;td&gt;
      HoneyBee: Efficient Role-based Access Control for Vector Databases via Dynamic Partitioning
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;
      Authors
    &lt;/td&gt;
    &lt;td&gt;
      Hongbin Zhong, Matthew Lentz, Nina Narodytska, Adriana Szekeres, Kexin Rong 
    &lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
   &lt;td&gt;
      Abstract
    &lt;/td&gt;
    &lt;td&gt;
      As vector databases gain traction in enterprise applications, robust access control has become critical to safeguard sensitive data. Access control in these systems is often implemented through hybrid vector queries, which combine nearest neighbor search on vector data with relational predicates based on user permissions. However, existing approaches face significant trade-offs: creating dedicated indexes for each user minimizes query latency but introduces excessive storage redundancy, while building a single index and applying access control after vector search reduces storage overhead but suffers from poor recall and increased query latency. This paper introduces HoneyBee, a dynamic partitioning framework that bridges the gap between these approaches by leveraging the structure of Role-Based Access Control (RBAC) policies. RBAC, widely adopted in enterprise settings, groups users into roles and assigns permissions to those roles, creating a natural &#34;thin waist&#34; in the permission structure that is ideal for partitioning decisions. Specifically, HoneyBee produces overlapping partitions where vectors can be strategically replicated across different partitions to reduce query latency while controlling storage overhead. By introducing analytical models for the performance and recall of the vector search, HoneyBee formulates the partitioning strategy as a constrained optimization problem to dynamically balance storage, query efficiency, and recall. Evaluations on RBAC workloads demonstrate that HoneyBee reduces storage redundancy compared to role partitioning and achieves up to 6x faster query speeds than row-level security (RLS) with only 1.4x storage increase, offering a practical middle ground for secure and efficient vector search.
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Summer 2025 Week 2</title>
      <link>https://diprlab.github.io/dbrg/events/2025/summer/02/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://diprlab.github.io/dbrg/events/2025/summer/02/</guid>
      <description>&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Title
    &lt;/td&gt;
    &lt;td&gt;
      An Elephant Under the Microscope: Analyzing the Interaction of Optimizer Components in PostgreSQL
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;
      Authors
    &lt;/td&gt;
    &lt;td&gt;
      Rico Bergmann, Claudio Hartmann, Dirk Habich, Wolfgang Lehner
    &lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
   &lt;td&gt;
      Abstract
    &lt;/td&gt;
    &lt;td&gt;
      Despite an ever-growing corpus of novel query optimization strategies, the interaction of the core components of query optimizers is still not well understood. This situation can be problematic for two main reasons: On the one hand, this may cause surprising results when two components influence each other in an unexpected way. On the other hand, this can lead to wasted effort in regard to both engineering and research, e.g., when an improvement for one component is dwarfed or entirely canceled out by problems of another component. Therefore, we argue that making improvements to a single optimization component requires a thorough understanding of how these changes might affect the other components. To achieve this understanding, we present results of a comprehensive experimental analysis of the interplay in the traditional optimizer architecture using the widely-used PostgreSQL system as prime representative. Our evaluation and analysis revisit the core building blocks of such an optimizer, i.e. per-column statistics, cardinality estimation, cost model, and plan generation. In particular, we analyze how these building blocks influence each other and how they react when faced with faulty input, such as imprecise cardinality estimates. Based on our results, we draw novel conclusions and make recommendations on how these should be taken into account.
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Summer 2025 Week 1</title>
      <link>https://diprlab.github.io/dbrg/events/2025/summer/01/</link>
      <pubDate>Wed, 09 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://diprlab.github.io/dbrg/events/2025/summer/01/</guid>
      <description>&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Title
    &lt;/td&gt;
    &lt;td&gt;
      Streaming Democratized: Ease Across the Latency Spectrum with Delayed View Semantics and Snowflake Dynamic Tables
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;
      Authors
    &lt;/td&gt;
    &lt;td&gt;
      Daniel Sotolongo, Daniel Mills, Tyler Akidau, Anirudh Santhiar, Attila-PÃ©ter TÃ³th, Botong Huang, Boyuan Zhang, Igor Belianski, Ling Geng, Matt Uhlar, Nikhil Shah, Olivia Zhou, Saras Nowak, Sasha Lionheart, Vlad Lifliand, Wendy Grus, Yiwen Zhu, Ankur Sharma, Dzmitry Pauliukevich, Enrico Sartorello, Ilaria Battiston, Ivan Kalev, Lawrence Benson, Leon Papke, Niklas Semmler, Till Merker, Yi Huang
    &lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
   &lt;td&gt;
      Abstract
    &lt;/td&gt;
    &lt;td&gt;
      Streaming data pipelines remain challenging and expensive to build and maintain, despite significant advancements in stronger consistency, event time semantics, and SQL support over the last decade. Persistent obstacles continue to hinder usability, such as the need for manual incrementalization, semantic discrepancies across SQL implementations, and the lack of enterprise-grade operational features (e.g. granular access control, disaster recovery). While the rise of incremental view maintenance (IVM) as a way to integrate streaming with databases has been a huge step forward, transaction isolation in the presence of IVM remains underspecified, which leaves the maintenance of application-level invariants as a painful exercise for the user. Meanwhile, most streaming systems optimize for latencies of 100 milliseconds to 3 seconds, whereas many practical use cases are well-served by latencies ranging from seconds to tens of minutes.
&lt;p&gt;In this paper, we present delayed view semantics (DVS), a conceptual foundation that bridges the semantic gap between streaming and databases, and introduce Dynamic Tables, Snowflake&amp;rsquo;s declarative streaming transformation primitive designed to democratize analytical stream processing. DVS formalizes the intuition that stream processing is primarily a technique to eagerly compute derived results asynchronously, while also addressing the need to reason about the resulting system end to end. Dynamic Tables then offer two key advantages: ease of use through DVS, enterprise-grade features, and simplicity; as well as scalable cost efficiency via IVM with an architecture designed for diverse latency requirements. We first develop extensions to transaction isolation that permit the preservation of invariants in streaming applications. We then detail the implementation challenges of Dynamic Tables and our experience operating it at scale. Finally, we share insights into user adoption and discuss our vision for the future of stream processing.&lt;/p&gt;
&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Spring 2025 Week 9</title>
      <link>https://diprlab.github.io/dbrg/events/2025/spring/09/</link>
      <pubDate>Fri, 30 May 2025 00:00:00 +0000</pubDate>
      <guid>https://diprlab.github.io/dbrg/events/2025/spring/09/</guid>
      <description>&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Title
    &lt;/td&gt;
    &lt;td&gt;
      In-Database Time Series Clustering
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;
      Authors
    &lt;/td&gt;
    &lt;td&gt;
      Yunxiang Su, Kenny Ye Liang, Shaoxu Song
    &lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
   &lt;td&gt;
      Abstract
    &lt;/td&gt;
    &lt;td&gt;
      Time series data are often clustered repeatedly across various time ranges to mine frequent subsequence patterns from different periods, which could further support downstream applications. Existing state-of-the-art (SOTA) time series clustering method, such as K-Shape, can proficiently cluster time series data referring to their shapes. However, in-database time series clustering problem has been neglected, especially in IoT scenarios with large-volume data and high efficiency demands. Most time series databases employ LSM-Tree based storage to support intensive writings, yet causing underlying data points out-of-order in timestamps. Therefore, to apply existing out-of-database methods, all data points must be fully loaded into memory and chronologically sorted. Additionally, out-of-database methods must cluster from scratch each time, making them inefficient when handling queries across different time ranges. In this work, we propose an in-database adaptation of SOTA time series clustering method K-Shape. Moreover, to solve the problem that K-Shape cannot efficiently handle long time series, we propose Medoid-Shape, as well as its in-database adaptation for further acceleration. Extensive experiments are conducted to demonstrate the higher efficiency of our proposals, with comparable effectiveness. Remarkably, all proposals have already been implemented in an open-source commodity time series database, Apache IoTDB.
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Spring 2025 Week 8</title>
      <link>https://diprlab.github.io/dbrg/events/2025/spring/08/</link>
      <pubDate>Fri, 23 May 2025 00:00:00 +0000</pubDate>
      <guid>https://diprlab.github.io/dbrg/events/2025/spring/08/</guid>
      <description>&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Title
    &lt;/td&gt;
    &lt;td&gt;
      Highly Efficient and Scalable Access Control Mechanism for IoT Devices in Pervasive Environments
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;
      Authors
    &lt;/td&gt;
    &lt;td&gt;
      Alian Yu, Jian Kang, Wei Jiang and Dan Lin
    &lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
   &lt;td&gt;
      Abstract
    &lt;/td&gt;
    &lt;td&gt;
      With the continuous advancement of sensing, networking, controlling, and computing technologies, there is a growing number of IoT (Internet of Things) devices emerging that are expected to integrate into public infrastructure in the near future. However, the deployment of these smart devices in public venues presents new challenges for existing access control mechanisms, particularly in terms of efficiency. To address these challenges, we have developed a highly efficient and scalable access control mechanism that enables automatic and fine-grained access control management while incurring low overhead in large-scale settings. Our mechanism includes a dual-hierarchy access control structure and associated information retrieval algorithms, which we have used to develop a large-scale IoT device access control system called FACT+. FACT+ overcomes the efficiency issues of granting and inquiring access control status over millions of devices in pervasive environments. Additionally, our system offers a pay-and-consume scheme and plug-and-play device management for convenient adoption by service providers. We have conducted extensive experiments to demonstrate the practicality, effectiveness, and efficiency of our access control mechanism.
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Spring 2025 Week 6</title>
      <link>https://diprlab.github.io/dbrg/events/2025/spring/06/</link>
      <pubDate>Fri, 09 May 2025 00:00:00 +0000</pubDate>
      <guid>https://diprlab.github.io/dbrg/events/2025/spring/06/</guid>
      <description>&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Title
    &lt;/td&gt;
    &lt;td&gt;
      Grouping, Subsumption, and Disjunctive Join Optimizations in Oracle
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;
      Authors
    &lt;/td&gt;
    &lt;td&gt;
      Rafi Ahmed, Krishna Kantikiran Pasupuleti, Sriram Tirupattur, Lei Sheng, Hong Su, Mohamed Ziauddin
    &lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
   &lt;td&gt;
      Abstract
    &lt;/td&gt;
    &lt;td&gt;
      Query optimization must evolve with new workloads. As analytic and data warehouse workloads become more ubiquitous, optimization techniques that reduce the amount of data processed during query execution, enable shared computation and avoid expensive data access and joins must be rigorously explored. In this paper, we present aggregate-decomposition techniques as enhancements to an existing query transformation that performs grouping before joins. Consequently, the transformation generates more query rewrite candidates and can also be applied to a larger set of queries. Further, we introduce two new query transformations, i) subsumption of views and subqueries that explores opportunities for sharing computation and ii) union-all duplicator transformation for queries with disjunctive join predicates that removes the need for multiple data access and joins. These techniques are applicable to commonly noticed query patterns in customer workloads and provide significant performance benefit as indicated in our performance study. They have been implemented in Oracle RDBMS.
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Spring 2025 Week 4</title>
      <link>https://diprlab.github.io/dbrg/events/2025/spring/04/</link>
      <pubDate>Fri, 25 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://diprlab.github.io/dbrg/events/2025/spring/04/</guid>
      <description>&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Title
    &lt;/td&gt;
    &lt;td&gt;
      How good are query optimizers, really?
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;
      Authors
    &lt;/td&gt;
    &lt;td&gt;
      Viktor Leis, Andrey Gubichev, Atanas Mirchev, Peter Boncz, Alfons Kemper, Thomas Neumann
    &lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
   &lt;td&gt;
      Abstract
    &lt;/td&gt;
    &lt;td&gt;
      Finding a good join order is crucial for query performance. In this paper, we introduce the Join Order Benchmark (JOB) and experimentally revisit the main components in the classic query optimizer architecture using a complex, real-world data set and realistic multi-join queries. We investigate the quality of industrial-strength cardinality estimators and find that all estimators routinely produce large errors. We further show that while estimates are essential for finding a good join order, query performance is unsatisfactory if the query engine relies too heavily on these estimates. Using another set of experiments that measure the impact of the cost model, we find that it has much less influence on query performance than the cardinality estimates. Finally, we investigate plan enumeration techniques comparing exhaustive dynamic programming with heuristic algorithms and find that exhaustive enumeration improves performance despite the sub-optimal cardinality estimates.
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Spring 2025 Week 3</title>
      <link>https://diprlab.github.io/dbrg/events/2025/spring/03/</link>
      <pubDate>Fri, 18 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://diprlab.github.io/dbrg/events/2025/spring/03/</guid>
      <description>&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Title
    &lt;/td&gt;
    &lt;td&gt;
      PDX: A Data Layout for Vector Similarity Search
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;
      Authors
    &lt;/td&gt;
    &lt;td&gt;
      Leonardo Kuffo, Elena Krippner, and Peter Boncz from CWI Amsterdam, The Netherlands
    &lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
   &lt;td&gt;
      Abstract
    &lt;/td&gt;
    &lt;td&gt;
      We propose Partition Dimensions Across (PDX), a data layout for vectors (e.g., embeddings) that, similar to PAX, stores multiple vectors in one block, using a vertical layout for the dimensions (Figure 1). PDX accelerates exact and approximate similarity search thanks to its dimension-by-dimension search strategy that operates on multiple-vectors-at-a-time in tight loops. It beats SIMD-optimized distance kernels on standard horizontal vector storage (avg 40% faster), only relying on scalar code that gets auto-vectorized. We combined the PDX layout with recent dimension-pruning algorithms ADSampling and BSA that accelerate approximate vector search. We found that these algorithms on the horizontal vector layout can lose to SIMD-optimized linear scans, even if they are SIMD-optimized. However, when used on PDX, their benefit is restored to 2-7x. We find that search on PDX is especially fast if a limited number of dimensions has to be scanned fully, which is what the dimension-pruning approaches do. We finally introduce PDX-BOND, an even more flexible dimension-pruning strategy, with good performance on exact search and reasonable performance on approximate search. Unlike previous pruning algorithms, it can work on vector data &#34;as-is&#34; without preprocessing; making it attractive for vector databases with frequent updates.
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Spring 2025 Week 1</title>
      <link>https://diprlab.github.io/dbrg/events/2025/spring/01/</link>
      <pubDate>Fri, 04 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://diprlab.github.io/dbrg/events/2025/spring/01/</guid>
      <description>&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      Title
    &lt;/td&gt;
    &lt;td&gt;
      Navigating Labels and Vectors: A Unified Approach to Filtered Approximate Nearest Neighbor Search
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td&gt;
      Authors
    &lt;/td&gt;
    &lt;td&gt;
      Yuzheng Cai, Jiayang Shi, Yizhuo Chen, Weigue Zheng
    &lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
   &lt;td&gt;
      Abstract
    &lt;/td&gt;
    &lt;td&gt;
      Given a query vector, approximate nearest neighbor search (ANNS) aims to retrieve similar vectors from a set of high-dimensional base vectors. However, many real-world applications jointly query both vector data and structured data, imposing label constraints such as attributes and keywords on the search, known as filtered ANNS. Effectively incorporating filtering conditions with vector similarity presents significant challenges, including index for dynamically filtered search space, agnostic query labels, computational overhead for label-irrelevant vectors, and potential inadequacy in returning results. To tackle these challenges, we introduce a novel approach called the Label Navigating Graph, which encodes the containment relationships of label sets for all vectors. Built upon graph-based ANNS methods, we develop a general framework termed Unified Navigating Graph (UNG) to bridge the gap between label set containment and vector proximity relations. UNG offers several advantages, including versatility in supporting any query label size and specificity, fidelity in exclusively searching filtered vectors, completeness in providing sufficient answers, and adaptability in integration with most graph-based ANNS algorithms. Extensive experiments on real datasets demonstrate that the proposed framework outperforms all baselines, achieving 10x speedups at the same accuracy.
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
  </channel>
</rss>
